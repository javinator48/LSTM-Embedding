{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Vanila_LSTM_spam",
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjWPn-GiVGPf",
        "outputId": "518c2756-e2bd-4e0e-89dd-21cc952c1513"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "S7SfU_6lViKR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import logging\n",
        "import gzip\n",
        "import gensim \n",
        "import re\n",
        "import spacy\n",
        "import math\n",
        "from collections import Counter\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "import string\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n"
      ],
      "metadata": {
        "id": "-J5hIbSEaRPZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.cuda.is_available())\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "rItWBp7RJEQq",
        "outputId": "23ddbaf8-cc34-44a7-9f60-b80c6e046a7c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda:0'"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing & Loading data"
      ],
      "metadata": {
        "id": "3KGKdTO5W7AH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess "
      ],
      "metadata": {
        "id": "vNprrOxtXCMj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clothing Review Dataset"
      ],
      "metadata": {
        "id": "OyA2zPsboOln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset for clothing reviews\n",
        "\n",
        "\n",
        "spam = pd.read_csv(\"/content/drive/MyDrive/data /spam.csv\",encoding=\"latin1\")\n",
        "spam.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'],axis=1,inplace=True)\n",
        "spam = spam[['v2', 'v1']]\n",
        "spam.columns = ['content', 'detection']\n",
        "spam['content_length'] = spam['content'].apply(lambda x: len(x.split()))\n",
        "#reviews = pd.read_csv(\"/content/drive/MyDrive/data /Womens Clothing E-Commerce Reviews.csv\")\n",
        "#reviews = reviews.dropna()\n",
        "#print(reviews.shape)\n",
        "spam.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "imlvO0RAVl5k",
        "outputId": "51db2f3b-d699-4690-f4f4-d53a7d4dba6d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0156cad0-7b42-4b92-8586-4ee26959b1f9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>detection</th>\n",
              "      <th>content_length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>ham</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>ham</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>spam</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>ham</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>ham</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0156cad0-7b42-4b92-8586-4ee26959b1f9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0156cad0-7b42-4b92-8586-4ee26959b1f9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0156cad0-7b42-4b92-8586-4ee26959b1f9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                             content detection  content_length\n",
              "0  Go until jurong point, crazy.. Available only ...       ham              20\n",
              "1                      Ok lar... Joking wif u oni...       ham               6\n",
              "2  Free entry in 2 a wkly comp to win FA Cup fina...      spam              28\n",
              "3  U dun say so early hor... U c already then say...       ham              11\n",
              "4  Nah I don't think he goes to usf, he lives aro...       ham              13"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tracker = []\n",
        "for aDetection in spam['detection']: \n",
        "  if not(aDetection in tracker): \n",
        "    tracker.append(aDetection)\n",
        "print(len(tracker))\n",
        "\n",
        "number_Detection = {}\n",
        "index = 0\n",
        "for aDetection in tracker: \n",
        "  number_Detection[aDetection] = index \n",
        "  index = index + 1\n",
        "spam['detection'] = spam['detection'].apply(lambda x: number_Detection[x])\n",
        "# reviews['Title'] = reviews['Title'].fillna('')\n",
        "# reviews['Review Text'] = reviews['Review Text'].fillna('')\n",
        "# reviews['review'] = reviews['Title'] + ' ' + reviews['Review Text']"
      ],
      "metadata": {
        "id": "YAwCLy3fWxfM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fa21ba0-534a-448f-d1d9-9ee3a22f2c6d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spam.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "HOCT_TqfJMAs",
        "outputId": "911665d6-0624-4d7f-8ca3-e000cfbf99e8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1def0704-43f9-4de6-8473-031594b47b26\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>detection</th>\n",
              "      <th>content_length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>1</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1def0704-43f9-4de6-8473-031594b47b26')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1def0704-43f9-4de6-8473-031594b47b26 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1def0704-43f9-4de6-8473-031594b47b26');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                             content  detection  content_length\n",
              "0  Go until jurong point, crazy.. Available only ...          0              20\n",
              "1                      Ok lar... Joking wif u oni...          0               6\n",
              "2  Free entry in 2 a wkly comp to win FA Cup fina...          1              28\n",
              "3  U dun say so early hor... U c already then say...          0              11\n",
              "4  Nah I don't think he goes to usf, he lives aro...          0              13"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reviews = reviews[['review', 'Rating']]\n",
        "# reviews.columns = ['review', 'rating']\n",
        "# reviews.head()\n",
        "spam = spam[['content', 'detection']]\n",
        "spam.columns = ['content', 'detection']\n",
        "spam.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "uJOEZcK9W1Xg",
        "outputId": "c43b45e7-cbe8-4c3c-9021-35a45aeaef8d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-fc080665-ac8b-4939-b224-8d953ec16fc6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>detection</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fc080665-ac8b-4939-b224-8d953ec16fc6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fc080665-ac8b-4939-b224-8d953ec16fc6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fc080665-ac8b-4939-b224-8d953ec16fc6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                             content  detection\n",
              "0  Go until jurong point, crazy.. Available only ...          0\n",
              "1                      Ok lar... Joking wif u oni...          0\n",
              "2  Free entry in 2 a wkly comp to win FA Cup fina...          1\n",
              "3  U dun say so early hor... U c already then say...          0\n",
              "4  Nah I don't think he goes to usf, he lives aro...          0"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tokenize each sentence"
      ],
      "metadata": {
        "id": "nln320q7XrNd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#take advantage of nltk to tokenize all sentences\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('stopwords')\n",
        "en_stop_words = set(stopwords.words('english'))\n",
        "tokenizer = nltk.RegexpTokenizer(r'\\w+|\\$[\\d\\.]+')\n",
        "\n",
        "def tokenize_sent(sent):\n",
        "    \n",
        "    tokenized = tokenizer.tokenize(sent)\n",
        "    filtered = [w.lower() for w in tokenized if w.lower() not in en_stop_words]\n",
        "    return filtered\n",
        "\n",
        "spam['tokenized'] = spam['content'].apply(lambda x: tokenize_sent(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PY9XLpc1Lbda",
        "outputId": "41f66810-efb2-4055-df95-3ffa56d38911"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sanity cehck for tokenizers\n",
        "print(spam.head(3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQnOPLzaM-IQ",
        "outputId": "e39158e5-03f2-4531-ed68-8a27253512bd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             content  ...                                          tokenized\n",
            "0  Go until jurong point, crazy.. Available only ...  ...  [go, jurong, point, crazy, available, bugis, n...\n",
            "1                      Ok lar... Joking wif u oni...  ...                     [ok, lar, joking, wif, u, oni]\n",
            "2  Free entry in 2 a wkly comp to win FA Cup fina...  ...  [free, entry, 2, wkly, comp, win, fa, cup, fin...\n",
            "\n",
            "[3 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Encode and truncate sentence"
      ],
      "metadata": {
        "id": "jJlI6cYBYXbw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get unique words in the corpus\n",
        "all_words = []\n",
        "for x in spam['tokenized']:\n",
        "    all_words.extend(x)\n",
        "\n",
        "word_set = list(set(all_words))\n",
        "word_count = Counter(all_words)\n",
        "\n",
        "# filter out words with low frequency\n",
        "for word_list in spam.tokenized:\n",
        "    new_list = []\n",
        "    for word in word_list:\n",
        "        if word_count[word] > 2:\n",
        "            new_list.append(word)\n",
        "    word_list = new_list\n",
        "\n",
        "# update set of words after removing the ones with low frequency\n",
        "new_word_list = []\n",
        "for x in spam['tokenized']:\n",
        "    new_word_list.extend(x)\n",
        "word_set = list(set(new_word_list))\n",
        "\n",
        "# map each unique words & unknown token in reviews.encoded to an index\n",
        "word2index = {}\n",
        "word2index['<UNK>'] = 0\n",
        "word2index['<PAD>'] = 1\n",
        "\n",
        "for i, word in enumerate(word_set, 2):\n",
        "    word2index[word] = i\n",
        "\n",
        "# encode the original sequence\n",
        "def encode(sent_list):\n",
        "    result = []\n",
        "    for x in sent_list:\n",
        "        index = word2index[x]\n",
        "        result.append(index)\n",
        "    return result\n",
        "\n",
        "spam['encoded'] = spam.tokenized.apply(lambda x: encode(x))\n",
        "\n",
        "print(spam.head())\n",
        "\n",
        "# get sequence average length\n",
        "total_len = 0\n",
        "for x in spam.encoded:\n",
        "    total_len += len(x)\n",
        "\n",
        "ave_len = math.floor(total_len/spam.shape[0])\n",
        "\n",
        "# filter out long sequences --> encode all sequence to length = ave_len\n",
        "# pad short sequence\n",
        "\n",
        "for i, row in spam.iterrows():\n",
        "    size = min(len(row.encoded), ave_len)\n",
        "    new_encoded = row.encoded[:size]\n",
        "    if size < ave_len:\n",
        "        for j in range(0, ave_len - len(row.encoded)):\n",
        "            new_encoded.append(1)\n",
        "    spam.at[i, 'encoded'] = new_encoded\n",
        "\n",
        "spam['review_length'] = spam.encoded.apply(lambda x: len(x))"
      ],
      "metadata": {
        "id": "-sT1ynqj_7Fo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0709467-1859-4fb0-aa45-ae05d95124de"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             content  ...                                            encoded\n",
            "0  Go until jurong point, crazy.. Available only ...  ...  [3194, 1875, 4828, 7044, 5523, 6292, 5095, 334...\n",
            "1                      Ok lar... Joking wif u oni...  ...                [4382, 5733, 8411, 8301, 1827, 593]\n",
            "2  Free entry in 2 a wkly comp to win FA Cup fina...  ...  [2784, 4004, 4322, 2887, 6307, 2658, 2107, 647...\n",
            "3  U dun say so early hor... U c already then say...  ...  [1827, 7942, 2349, 401, 5292, 1827, 6794, 8354...\n",
            "4  Nah I don't think he goes to usf, he lives aro...  ...          [7668, 3948, 147, 4748, 6178, 3142, 1458]\n",
            "\n",
            "[5 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sanity check for encoding:\n",
        "print(len(all_words))\n",
        "print(ave_len)\n",
        "lengths = [len(x) for x in spam.encoded]\n",
        "print(max(lengths))\n",
        "print(min(lengths))\n",
        "print(set(spam.detection))\n",
        "review_length = spam.review_length\n",
        "spam.head()\n",
        "print(len(word_set))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lNy_oCSFrqf",
        "outputId": "92db02fb-8391-44c7-d778-0de717b7113e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53413\n",
            "9\n",
            "9\n",
            "9\n",
            "{0, 1}\n",
            "8577\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train test split from skearln\n",
        "data_size = len(spam['encoded'])\n",
        "assert data_size == len(spam['detection']) \n",
        "X, y = list(zip(list(spam['encoded']),(list(spam['review_length'])))), list(spam['detection'])\n",
        "# X(data, length)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=43)"
      ],
      "metadata": {
        "id": "glkjNVF-N_0r"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_new=[]\n",
        "for tup in X_train:\n",
        "  arr = np.asarray(tup)\n",
        "  X_train_new.append(arr)\n",
        "\n",
        "X_test_new=[]\n",
        "for tup in X_test:\n",
        "  arr = np.asarray(tup)\n",
        "  X_test_new.append(arr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "932iILHD_94e",
        "outputId": "fbe495af-8a53-4942-edd7-b6cee4f90e50"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sanity check for length match\n",
        "print(X_train_new[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlveD7X5cPYp",
        "outputId": "d01ccd70-02c0-46a9-d830-dd6bbaf6fe71"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[list([3567, 1240, 3734, 5492, 7159, 1240, 459, 3360, 4444]) 9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset and Dataloader"
      ],
      "metadata": {
        "id": "53k_akR7YiAl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clothing Review Dataset"
      ],
      "metadata": {
        "id": "5jGEsKl8obJ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# class Dataset_Glove(Dataset):\n",
        "#     def __init__(self, X, y): \n",
        "#         self.X = X\n",
        "#         self.y = y\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.X)\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         return  self.X[idx], self.y[idx]\n"
      ],
      "metadata": {
        "id": "nmCLiMzCY-o3"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ReviewsDataset(Dataset):\n",
        "    def __init__(self, X, Y):\n",
        "        self.X = X\n",
        "        self.y = Y\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return torch.from_numpy(np.array(self.X[idx][0])), self.y[idx], self.X[idx][1]"
      ],
      "metadata": {
        "id": "1iw5MXNKqW9k"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# trainSet_glv = Dataset_Glove(X_train, y_train)\n",
        "# testSet_glv = Dataset_Glove(X_test, y_test)\n",
        "train_ds = ReviewsDataset(X_train_new, y_train)\n",
        "valid_ds = ReviewsDataset(X_test_new, y_test)"
      ],
      "metadata": {
        "id": "yf03irQDieWM"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zCt282rkny8w"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, epochs=10, lr=0.001):\n",
        "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "    optimizer = torch.optim.Adam(parameters, lr=lr)\n",
        "    epoch = 0\n",
        "    best_val_acc = 0.0  \n",
        "    for i in range(epochs):\n",
        "        model.train()\n",
        "        sum_loss = 0.0\n",
        "        batch_count=0\n",
        "        total = 0\n",
        "        train_correct = 0.0\n",
        "        epoch += 1\n",
        "        print(f\"At epoch {i}\")\n",
        "        for x, y, l in train_dl:\n",
        "            x = x.long()\n",
        "            y = y.long()\n",
        "            batch_count+=1\n",
        "            optimizer.zero_grad()\n",
        "            y_pred = model(x, l)\n",
        "            pred = torch.argmax(y_pred, 1)\n",
        "            train_correct += sum((pred == y))\n",
        "            loss = F.cross_entropy(y_pred, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            sum_loss += loss.item()*y.shape[0]\n",
        "            total += y.shape[0]\n",
        "        val_loss, val_acc, precision, recall, f1  = validation_metrics(model, val_dl)\n",
        "        print(\"train loss %.3f, train accuracy %.3f, val loss %.3f, val accuracy %.3f, precision %.3f, recall %.3f, F1 %.3f\" \n",
        "              % (sum_loss/total, train_correct/total, val_loss, val_acc, precision, recall, f1))\n",
        "        if val_acc > best_val_acc and i>=1:\n",
        "            best_val_acc = val_acc\n",
        "\n",
        "            #torch.save(model.state_dict(), NEW_PATH)\n",
        "            print(f\"\\t=> Best model saved at {i}th epoch with valication accuracy of {val_acc}\")\n",
        "def validation_metrics (model, valid_dl):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    sum_loss = 0.0\n",
        "    sum_rmse = 0.0\n",
        "    y_total = []\n",
        "    y_pred_total = []\n",
        "    for x, y, l in valid_dl:\n",
        "        x = x.long()\n",
        "        y = y.long()\n",
        "        y_hat = model(x, l)\n",
        "        loss = F.cross_entropy(y_hat, y)\n",
        "        pred = torch.max(y_hat, 1)[1]\n",
        "        y_total.extend(y.tolist())\n",
        "        y_pred_total.extend(pred.tolist())\n",
        "        correct += (pred == y).float().sum()\n",
        "        total += y.shape[0]\n",
        "        sum_loss += loss.item()*y.shape[0]\n",
        "        #sum_rmse += np.sqrt(mean_squared_error(pred, y.unsqueeze(-1)))*y.shape[0]\n",
        "\n",
        "    f1 = (f1_score(y_total, y_pred_total, average='weighted'))\n",
        "    precision = (precision_score(y_total, y_pred_total, average='weighted'))\n",
        "    recall =(recall_score(y_total, y_pred_total, average='weighted'))\n",
        "   \n",
        "    return sum_loss/total, correct/total,  precision, recall, f1\n"
      ],
      "metadata": {
        "id": "OfwYPLcKiiGm"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 5000\n",
        "vocab_size = len(word2index)\n",
        "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
        "val_dl = DataLoader(valid_ds, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "5UJ2oiTW8mYz"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gioWFxg7AWYZ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM_fixed_len(torch.nn.Module) :\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim) :\n",
        "        super().__init__()\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_dim, 5)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        \n",
        "    def forward(self, x, l):\n",
        "        x = self.embeddings(x)\n",
        "        x = self.dropout(x)\n",
        "        lstm_out, (ht, ct) = self.lstm(x)\n",
        "        return self.linear(ht[-1])"
      ],
      "metadata": {
        "id": "7YPo-9GMiiGm"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_fixed =  LSTM_fixed_len(vocab_size, 50, 50)\n",
        "train_model(model_fixed, epochs=30, lr=0.01)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jggaA1ttBz8W",
        "outputId": "bb6dd87c-8cd3-4e44-8caa-50cabd334621"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "At epoch 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 1.544, train accuracy 0.506, val loss 1.073, val accuracy 0.694, precision 0.862, recall 0.694, F1 0.768\n",
            "At epoch 1\n",
            "train loss 1.094, train accuracy 0.690, val loss 0.802, val accuracy 0.776, precision 0.845, recall 0.776, F1 0.809\n",
            "\t=> Best model saved at 1th epoch with valication accuracy of 0.7757847309112549\n",
            "At epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.815, train accuracy 0.776, val loss 0.654, val accuracy 0.829, precision 0.829, recall 0.829, F1 0.826\n",
            "\t=> Best model saved at 2th epoch with valication accuracy of 0.82869952917099\n",
            "At epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.662, train accuracy 0.824, val loss 0.542, val accuracy 0.860, precision 0.835, recall 0.860, F1 0.834\n",
            "\t=> Best model saved at 3th epoch with valication accuracy of 0.8600896596908569\n",
            "At epoch 4\n",
            "train loss 0.544, train accuracy 0.856, val loss 0.457, val accuracy 0.861, precision 0.820, recall 0.861, F1 0.812\n",
            "\t=> Best model saved at 4th epoch with valication accuracy of 0.8609865307807922\n",
            "At epoch 5\n",
            "train loss 0.444, train accuracy 0.874, val loss 0.462, val accuracy 0.864, precision 0.855, recall 0.864, F1 0.805\n",
            "\t=> Best model saved at 5th epoch with valication accuracy of 0.8636771440505981\n",
            "At epoch 6\n",
            "train loss 0.424, train accuracy 0.873, val loss 0.485, val accuracy 0.864, precision 0.882, recall 0.864, F1 0.803\n",
            "At epoch 7\n",
            "train loss 0.438, train accuracy 0.876, val loss 0.450, val accuracy 0.866, precision 0.884, recall 0.866, F1 0.809\n",
            "\t=> Best model saved at 7th epoch with valication accuracy of 0.8663676977157593\n",
            "At epoch 8\n",
            "train loss 0.392, train accuracy 0.880, val loss 0.388, val accuracy 0.880, precision 0.895, recall 0.880, F1 0.838\n",
            "\t=> Best model saved at 8th epoch with valication accuracy of 0.8798206448554993\n",
            "At epoch 9\n",
            "train loss 0.336, train accuracy 0.891, val loss 0.334, val accuracy 0.894, precision 0.896, recall 0.894, F1 0.868\n",
            "\t=> Best model saved at 9th epoch with valication accuracy of 0.8941704034805298\n",
            "At epoch 10\n",
            "train loss 0.293, train accuracy 0.907, val loss 0.302, val accuracy 0.902, precision 0.903, recall 0.902, F1 0.882\n",
            "\t=> Best model saved at 10th epoch with valication accuracy of 0.902242124080658\n",
            "At epoch 11\n",
            "train loss 0.266, train accuracy 0.919, val loss 0.289, val accuracy 0.914, precision 0.913, recall 0.914, F1 0.900\n",
            "\t=> Best model saved at 11th epoch with valication accuracy of 0.9139013290405273\n",
            "At epoch 12\n",
            "train loss 0.258, train accuracy 0.930, val loss 0.282, val accuracy 0.921, precision 0.917, recall 0.921, F1 0.913\n",
            "\t=> Best model saved at 12th epoch with valication accuracy of 0.921076238155365\n",
            "At epoch 13\n",
            "train loss 0.253, train accuracy 0.939, val loss 0.272, val accuracy 0.921, precision 0.916, recall 0.921, F1 0.915\n",
            "At epoch 14\n",
            "train loss 0.243, train accuracy 0.943, val loss 0.256, val accuracy 0.929, precision 0.925, recall 0.929, F1 0.924\n",
            "\t=> Best model saved at 14th epoch with valication accuracy of 0.9291479587554932\n",
            "At epoch 15\n",
            "train loss 0.226, train accuracy 0.951, val loss 0.237, val accuracy 0.934, precision 0.931, recall 0.934, F1 0.929\n",
            "\t=> Best model saved at 15th epoch with valication accuracy of 0.9336323142051697\n",
            "At epoch 16\n",
            "train loss 0.206, train accuracy 0.957, val loss 0.219, val accuracy 0.932, precision 0.929, recall 0.932, F1 0.926\n",
            "At epoch 17\n",
            "train loss 0.181, train accuracy 0.959, val loss 0.203, val accuracy 0.936, precision 0.935, recall 0.936, F1 0.930\n",
            "\t=> Best model saved at 17th epoch with valication accuracy of 0.9363228678703308\n",
            "At epoch 18\n",
            "train loss 0.161, train accuracy 0.964, val loss 0.192, val accuracy 0.939, precision 0.940, recall 0.939, F1 0.933\n",
            "\t=> Best model saved at 18th epoch with valication accuracy of 0.9390134811401367\n",
            "At epoch 19\n",
            "train loss 0.140, train accuracy 0.968, val loss 0.184, val accuracy 0.940, precision 0.940, recall 0.940, F1 0.934\n",
            "\t=> Best model saved at 19th epoch with valication accuracy of 0.9399102926254272\n",
            "At epoch 20\n",
            "train loss 0.127, train accuracy 0.967, val loss 0.178, val accuracy 0.943, precision 0.943, recall 0.943, F1 0.937\n",
            "\t=> Best model saved at 20th epoch with valication accuracy of 0.9426009058952332\n",
            "At epoch 21\n",
            "train loss 0.115, train accuracy 0.971, val loss 0.172, val accuracy 0.945, precision 0.946, recall 0.945, F1 0.941\n",
            "\t=> Best model saved at 21th epoch with valication accuracy of 0.9452914595603943\n",
            "At epoch 22\n",
            "train loss 0.105, train accuracy 0.973, val loss 0.164, val accuracy 0.947, precision 0.947, recall 0.947, F1 0.943\n",
            "\t=> Best model saved at 22th epoch with valication accuracy of 0.9470852017402649\n",
            "At epoch 23\n",
            "train loss 0.091, train accuracy 0.979, val loss 0.156, val accuracy 0.950, precision 0.949, recall 0.950, F1 0.947\n",
            "\t=> Best model saved at 23th epoch with valication accuracy of 0.949775755405426\n",
            "At epoch 24\n",
            "train loss 0.082, train accuracy 0.980, val loss 0.149, val accuracy 0.950, precision 0.948, recall 0.950, F1 0.947\n",
            "At epoch 25\n",
            "train loss 0.074, train accuracy 0.982, val loss 0.144, val accuracy 0.954, precision 0.953, recall 0.954, F1 0.952\n",
            "\t=> Best model saved at 25th epoch with valication accuracy of 0.9542601108551025\n",
            "At epoch 26\n",
            "train loss 0.067, train accuracy 0.984, val loss 0.141, val accuracy 0.956, precision 0.955, recall 0.956, F1 0.955\n",
            "\t=> Best model saved at 26th epoch with valication accuracy of 0.9560537934303284\n",
            "At epoch 27\n",
            "train loss 0.060, train accuracy 0.986, val loss 0.142, val accuracy 0.956, precision 0.955, recall 0.956, F1 0.955\n",
            "At epoch 28\n",
            "train loss 0.061, train accuracy 0.986, val loss 0.144, val accuracy 0.956, precision 0.955, recall 0.956, F1 0.955\n",
            "At epoch 29\n",
            "train loss 0.059, train accuracy 0.987, val loss 0.146, val accuracy 0.956, precision 0.955, recall 0.956, F1 0.955\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model_fixed, epochs=30, lr=0.01)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qd5W1PBlB4Cm",
        "outputId": "7e2cdc4e-1b23-460f-a880-67b67b231479"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "At epoch 0\n",
            "train loss 0.056, train accuracy 0.987, val loss 0.172, val accuracy 0.951, precision 0.950, recall 0.951, F1 0.948\n",
            "At epoch 1\n",
            "train loss 0.056, train accuracy 0.986, val loss 0.141, val accuracy 0.959, precision 0.958, recall 0.959, F1 0.957\n",
            "\t=> Best model saved at 1th epoch with valication accuracy of 0.9587444067001343\n",
            "At epoch 2\n",
            "train loss 0.046, train accuracy 0.990, val loss 0.124, val accuracy 0.961, precision 0.960, recall 0.961, F1 0.960\n",
            "\t=> Best model saved at 2th epoch with valication accuracy of 0.9605380892753601\n",
            "At epoch 3\n",
            "train loss 0.043, train accuracy 0.991, val loss 0.123, val accuracy 0.964, precision 0.964, recall 0.964, F1 0.964\n",
            "\t=> Best model saved at 3th epoch with valication accuracy of 0.9641255736351013\n",
            "At epoch 4\n",
            "train loss 0.041, train accuracy 0.991, val loss 0.121, val accuracy 0.967, precision 0.967, recall 0.967, F1 0.967\n",
            "\t=> Best model saved at 4th epoch with valication accuracy of 0.9668161273002625\n",
            "At epoch 5\n",
            "train loss 0.036, train accuracy 0.992, val loss 0.119, val accuracy 0.969, precision 0.968, recall 0.969, F1 0.968\n",
            "\t=> Best model saved at 5th epoch with valication accuracy of 0.9686098694801331\n",
            "At epoch 6\n",
            "train loss 0.030, train accuracy 0.993, val loss 0.124, val accuracy 0.969, precision 0.968, recall 0.969, F1 0.968\n",
            "At epoch 7\n",
            "train loss 0.027, train accuracy 0.994, val loss 0.134, val accuracy 0.967, precision 0.966, recall 0.967, F1 0.966\n",
            "At epoch 8\n",
            "train loss 0.026, train accuracy 0.994, val loss 0.140, val accuracy 0.968, precision 0.967, recall 0.968, F1 0.967\n",
            "At epoch 9\n",
            "train loss 0.026, train accuracy 0.993, val loss 0.144, val accuracy 0.968, precision 0.967, recall 0.968, F1 0.967\n",
            "At epoch 10\n",
            "train loss 0.020, train accuracy 0.995, val loss 0.145, val accuracy 0.967, precision 0.966, recall 0.967, F1 0.966\n",
            "At epoch 11\n",
            "train loss 0.021, train accuracy 0.995, val loss 0.142, val accuracy 0.967, precision 0.966, recall 0.967, F1 0.966\n",
            "At epoch 12\n",
            "train loss 0.016, train accuracy 0.996, val loss 0.138, val accuracy 0.968, precision 0.967, recall 0.968, F1 0.967\n",
            "At epoch 13\n",
            "train loss 0.017, train accuracy 0.995, val loss 0.136, val accuracy 0.968, precision 0.967, recall 0.968, F1 0.967\n",
            "At epoch 14\n",
            "train loss 0.014, train accuracy 0.997, val loss 0.134, val accuracy 0.969, precision 0.968, recall 0.969, F1 0.968\n",
            "At epoch 15\n",
            "train loss 0.012, train accuracy 0.997, val loss 0.133, val accuracy 0.969, precision 0.968, recall 0.969, F1 0.968\n",
            "At epoch 16\n",
            "train loss 0.012, train accuracy 0.997, val loss 0.135, val accuracy 0.970, precision 0.969, recall 0.970, F1 0.969\n",
            "\t=> Best model saved at 16th epoch with valication accuracy of 0.9695067405700684\n",
            "At epoch 17\n",
            "train loss 0.011, train accuracy 0.998, val loss 0.137, val accuracy 0.970, precision 0.969, recall 0.970, F1 0.969\n",
            "At epoch 18\n",
            "train loss 0.008, train accuracy 0.998, val loss 0.140, val accuracy 0.970, precision 0.969, recall 0.970, F1 0.969\n",
            "At epoch 19\n",
            "train loss 0.007, train accuracy 0.998, val loss 0.143, val accuracy 0.970, precision 0.969, recall 0.970, F1 0.969\n",
            "At epoch 20\n",
            "train loss 0.007, train accuracy 0.999, val loss 0.145, val accuracy 0.970, precision 0.969, recall 0.970, F1 0.969\n",
            "At epoch 21\n",
            "train loss 0.006, train accuracy 0.999, val loss 0.149, val accuracy 0.969, precision 0.968, recall 0.969, F1 0.968\n",
            "At epoch 22\n",
            "train loss 0.005, train accuracy 0.999, val loss 0.152, val accuracy 0.969, precision 0.968, recall 0.969, F1 0.968\n",
            "At epoch 23\n",
            "train loss 0.004, train accuracy 0.999, val loss 0.155, val accuracy 0.970, precision 0.970, recall 0.970, F1 0.969\n",
            "\t=> Best model saved at 23th epoch with valication accuracy of 0.9704036116600037\n",
            "At epoch 24\n",
            "train loss 0.004, train accuracy 0.999, val loss 0.158, val accuracy 0.970, precision 0.970, recall 0.970, F1 0.969\n",
            "At epoch 25\n",
            "train loss 0.004, train accuracy 0.999, val loss 0.162, val accuracy 0.970, precision 0.970, recall 0.970, F1 0.969\n",
            "At epoch 26\n",
            "train loss 0.004, train accuracy 0.999, val loss 0.166, val accuracy 0.969, precision 0.968, recall 0.969, F1 0.968\n",
            "At epoch 27\n",
            "train loss 0.004, train accuracy 0.999, val loss 0.167, val accuracy 0.970, precision 0.969, recall 0.970, F1 0.968\n",
            "At epoch 28\n",
            "train loss 0.003, train accuracy 0.999, val loss 0.168, val accuracy 0.970, precision 0.969, recall 0.970, F1 0.968\n",
            "At epoch 29\n",
            "train loss 0.002, train accuracy 0.999, val loss 0.170, val accuracy 0.969, precision 0.968, recall 0.969, F1 0.968\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model_fixed, epochs=30, lr=0.01)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZuXxVlNB4oo",
        "outputId": "ecc4cf80-19dd-484f-810a-2db81c17a4ce"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "At epoch 0\n",
            "train loss 0.002, train accuracy 0.999, val loss 0.205, val accuracy 0.966, precision 0.965, recall 0.966, F1 0.965\n",
            "At epoch 1\n",
            "train loss 0.002, train accuracy 1.000, val loss 0.194, val accuracy 0.967, precision 0.966, recall 0.967, F1 0.966\n",
            "\t=> Best model saved at 1th epoch with valication accuracy of 0.9668161273002625\n",
            "At epoch 2\n",
            "train loss 0.002, train accuracy 1.000, val loss 0.184, val accuracy 0.968, precision 0.967, recall 0.968, F1 0.967\n",
            "\t=> Best model saved at 2th epoch with valication accuracy of 0.9677129983901978\n",
            "At epoch 3\n",
            "train loss 0.002, train accuracy 1.000, val loss 0.166, val accuracy 0.970, precision 0.970, recall 0.970, F1 0.970\n",
            "\t=> Best model saved at 3th epoch with valication accuracy of 0.9704036116600037\n",
            "At epoch 4\n",
            "train loss 0.001, train accuracy 1.000, val loss 0.158, val accuracy 0.969, precision 0.968, recall 0.969, F1 0.968\n",
            "At epoch 5\n",
            "train loss 0.001, train accuracy 1.000, val loss 0.154, val accuracy 0.970, precision 0.969, recall 0.970, F1 0.969\n",
            "At epoch 6\n",
            "train loss 0.001, train accuracy 1.000, val loss 0.162, val accuracy 0.970, precision 0.970, recall 0.970, F1 0.970\n",
            "At epoch 7\n",
            "train loss 0.000, train accuracy 1.000, val loss 0.175, val accuracy 0.967, precision 0.966, recall 0.967, F1 0.966\n",
            "At epoch 8\n",
            "train loss 0.000, train accuracy 1.000, val loss 0.190, val accuracy 0.966, precision 0.965, recall 0.966, F1 0.965\n",
            "At epoch 9\n",
            "train loss 0.000, train accuracy 1.000, val loss 0.202, val accuracy 0.966, precision 0.965, recall 0.966, F1 0.965\n",
            "At epoch 10\n",
            "train loss 0.000, train accuracy 1.000, val loss 0.216, val accuracy 0.966, precision 0.966, recall 0.966, F1 0.964\n",
            "At epoch 11\n",
            "train loss 0.001, train accuracy 1.000, val loss 0.214, val accuracy 0.967, precision 0.966, recall 0.967, F1 0.966\n",
            "At epoch 12\n",
            "train loss 0.000, train accuracy 1.000, val loss 0.212, val accuracy 0.969, precision 0.968, recall 0.969, F1 0.968\n",
            "At epoch 13\n",
            "train loss 0.000, train accuracy 1.000, val loss 0.202, val accuracy 0.969, precision 0.968, recall 0.969, F1 0.968\n",
            "At epoch 14\n",
            "train loss 0.000, train accuracy 1.000, val loss 0.193, val accuracy 0.970, precision 0.970, recall 0.970, F1 0.970\n",
            "At epoch 15\n",
            "train loss 0.000, train accuracy 1.000, val loss 0.188, val accuracy 0.970, precision 0.970, recall 0.970, F1 0.970\n",
            "At epoch 16\n",
            "train loss 0.000, train accuracy 1.000, val loss 0.185, val accuracy 0.971, precision 0.971, recall 0.971, F1 0.971\n",
            "\t=> Best model saved at 16th epoch with valication accuracy of 0.9713004231452942\n",
            "At epoch 17\n",
            "train loss 0.000, train accuracy 1.000, val loss 0.184, val accuracy 0.970, precision 0.970, recall 0.970, F1 0.970\n",
            "At epoch 18\n",
            "train loss 0.000, train accuracy 1.000, val loss 0.187, val accuracy 0.969, precision 0.968, recall 0.969, F1 0.968\n",
            "At epoch 19\n",
            "train loss 0.000, train accuracy 1.000, val loss 0.191, val accuracy 0.969, precision 0.968, recall 0.969, F1 0.968\n",
            "At epoch 20\n",
            "train loss 0.000, train accuracy 1.000, val loss 0.193, val accuracy 0.969, precision 0.968, recall 0.969, F1 0.968\n",
            "At epoch 21\n",
            "train loss 0.000, train accuracy 1.000, val loss 0.197, val accuracy 0.968, precision 0.967, recall 0.968, F1 0.967\n",
            "At epoch 22\n",
            "train loss 0.000, train accuracy 1.000, val loss 0.190, val accuracy 0.968, precision 0.967, recall 0.968, F1 0.967\n",
            "At epoch 23\n",
            "train loss 0.000, train accuracy 1.000, val loss 0.184, val accuracy 0.969, precision 0.968, recall 0.969, F1 0.968\n",
            "At epoch 24\n",
            "train loss 0.000, train accuracy 1.000, val loss 0.180, val accuracy 0.970, precision 0.969, recall 0.970, F1 0.969\n",
            "At epoch 25\n",
            "train loss 0.000, train accuracy 1.000, val loss 0.177, val accuracy 0.970, precision 0.970, recall 0.970, F1 0.970\n",
            "At epoch 26\n",
            "train loss 0.000, train accuracy 1.000, val loss 0.178, val accuracy 0.966, precision 0.965, recall 0.966, F1 0.965\n",
            "At epoch 27\n",
            "train loss 0.000, train accuracy 1.000, val loss 0.188, val accuracy 0.965, precision 0.964, recall 0.965, F1 0.964\n",
            "At epoch 28\n",
            "train loss 0.000, train accuracy 1.000, val loss 0.199, val accuracy 0.967, precision 0.966, recall 0.967, F1 0.966\n",
            "At epoch 29\n",
            "train loss 0.000, train accuracy 1.000, val loss 0.211, val accuracy 0.963, precision 0.962, recall 0.963, F1 0.962\n"
          ]
        }
      ]
    }
  ]
}