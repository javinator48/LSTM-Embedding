{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word2Vec_LSTM_spam",
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjWPn-GiVGPf",
        "outputId": "e309cf3f-19c1-479b-fe6d-80cb329f0e2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DE-PaZNXrRNF",
        "outputId": "11da1c17-27f9-4478-dae0-59d1fa45a3bb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.14.1-py3-none-any.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 8.2 MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 5.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 54.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 689 kB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 64.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.2.1 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.14.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import logging\n",
        "import gzip\n",
        "import gensim \n",
        "import re\n",
        "import spacy\n",
        "import math\n",
        "from collections import Counter\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "import string\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence\n",
        "from transformers import BertTokenizer, BertModel, DistilBertConfig, TFDistilBertModel, DistilBertModel, DistilBertTokenizer\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "S7SfU_6lViKR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.cuda.is_available())\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "rItWBp7RJEQq",
        "outputId": "72aee7fa-a06d-448e-e2e7-64d07c118968"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda:0'"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing & Loading data"
      ],
      "metadata": {
        "id": "3KGKdTO5W7AH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess "
      ],
      "metadata": {
        "id": "vNprrOxtXCMj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clothing Review Dataset"
      ],
      "metadata": {
        "id": "OyA2zPsboOln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Load dataset for clothing reviews\n",
        "# reviews = pd.read_csv(\"/content/drive/MyDrive/data /Womens Clothing E-Commerce Reviews.csv\")\n",
        "# reviews = reviews.dropna()\n",
        "# print(reviews.shape)\n",
        "# reviews.head()\n",
        "# Load dataset for clothing reviews\n",
        "\n",
        "\n",
        "spam = pd.read_csv(\"/content/drive/MyDrive/data /spam.csv\",encoding=\"latin1\")\n",
        "spam.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'],axis=1,inplace=True)\n",
        "spam = spam[['v2', 'v1']]\n",
        "spam.columns = ['content', 'detection']\n",
        "spam['content_length'] = spam['content'].apply(lambda x: len(x.split()))\n",
        "spam.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "imlvO0RAVl5k",
        "outputId": "7d4bd3c4-8b44-44a1-9f13-b60e42bb5ea9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f42194f0-4a2a-4b30-b1df-5d2a6c47f9e0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>detection</th>\n",
              "      <th>content_length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>ham</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>ham</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>spam</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>ham</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>ham</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f42194f0-4a2a-4b30-b1df-5d2a6c47f9e0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f42194f0-4a2a-4b30-b1df-5d2a6c47f9e0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f42194f0-4a2a-4b30-b1df-5d2a6c47f9e0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                             content detection  content_length\n",
              "0  Go until jurong point, crazy.. Available only ...       ham              20\n",
              "1                      Ok lar... Joking wif u oni...       ham               6\n",
              "2  Free entry in 2 a wkly comp to win FA Cup fina...      spam              28\n",
              "3  U dun say so early hor... U c already then say...       ham              11\n",
              "4  Nah I don't think he goes to usf, he lives aro...       ham              13"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reviews['Title'] = reviews['Title'].fillna('')\n",
        "# reviews['Review Text'] = reviews['Review Text'].fillna('')\n",
        "# reviews['review'] = reviews['Title'] + ' ' + reviews['Review Text']\n",
        "tracker = []\n",
        "for aDetection in spam['detection']: \n",
        "  if not(aDetection in tracker): \n",
        "    tracker.append(aDetection)\n",
        "print(len(tracker))\n",
        "\n",
        "number_Detection = {}\n",
        "index = 0\n",
        "for aDetection in tracker: \n",
        "  number_Detection[aDetection] = index \n",
        "  index = index + 1\n",
        "spam['detection'] = spam['detection'].apply(lambda x: number_Detection[x])"
      ],
      "metadata": {
        "id": "YAwCLy3fWxfM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "484a3d2f-910c-4ef3-8b84-a06842a446df"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reviews = reviews[['review', 'Rating']]\n",
        "# reviews.columns = ['review', 'rating']\n",
        "# reviews.head()\n",
        "spam = spam[['content', 'detection']]\n",
        "spam.columns = ['content', 'detection']\n",
        "spam.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "uJOEZcK9W1Xg",
        "outputId": "b980513e-bca9-4676-bae6-a96c161a7e19"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-65a2ed8e-f3b7-47d0-a453-9fd971ac0281\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>detection</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-65a2ed8e-f3b7-47d0-a453-9fd971ac0281')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-65a2ed8e-f3b7-47d0-a453-9fd971ac0281 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-65a2ed8e-f3b7-47d0-a453-9fd971ac0281');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                             content  detection\n",
              "0  Go until jurong point, crazy.. Available only ...          0\n",
              "1                      Ok lar... Joking wif u oni...          0\n",
              "2  Free entry in 2 a wkly comp to win FA Cup fina...          1\n",
              "3  U dun say so early hor... U c already then say...          0\n",
              "4  Nah I don't think he goes to usf, he lives aro...          0"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tokenize each sentence"
      ],
      "metadata": {
        "id": "nln320q7XrNd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#take advantage of nltk to tokenize all sentences\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('stopwords')\n",
        "en_stop_words = set(stopwords.words('english'))\n",
        "tokenizer = nltk.RegexpTokenizer(r'\\w+|\\$[\\d\\.]+')\n",
        "\n",
        "def tokenize_sent(sent):\n",
        "    \n",
        "    tokenized = tokenizer.tokenize(sent)\n",
        "    filtered = [w.lower() for w in tokenized if w.lower() not in en_stop_words]\n",
        "    return filtered\n",
        "spam['tokenized'] = spam['content'].apply(lambda x: tokenize_sent(x))\n",
        "# reviews['tokenized'] = reviews['review'].apply(lambda x: tokenize_sent(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PY9XLpc1Lbda",
        "outputId": "e29c4aa1-8709-4bd0-e4fe-81d8514aed75"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sanity cehck for tokenizers\n",
        "print(spam.head(3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQnOPLzaM-IQ",
        "outputId": "38f7ebac-f524-4ed5-ad76-db5cc9940dc7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             content  ...                                          tokenized\n",
            "0  Go until jurong point, crazy.. Available only ...  ...  [go, jurong, point, crazy, available, bugis, n...\n",
            "1                      Ok lar... Joking wif u oni...  ...                     [ok, lar, joking, wif, u, oni]\n",
            "2  Free entry in 2 a wkly comp to win FA Cup fina...  ...  [free, entry, 2, wkly, comp, win, fa, cup, fin...\n",
            "\n",
            "[3 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Encode and truncate sentence"
      ],
      "metadata": {
        "id": "jJlI6cYBYXbw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # sanity check for encoding:\n",
        "# print(len(all_words))\n",
        "# print(ave_len)\n",
        "# lengths = [len(x) for x in reviews.encoded]\n",
        "# print(max(lengths))\n",
        "# print(min(lengths))\n",
        "# print(set(reviews.rating))\n",
        "# review_length = reviews.review_length\n",
        "# reviews.head()\n",
        "# print(len(word_set))"
      ],
      "metadata": {
        "id": "5lNy_oCSFrqf"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get unique words in the corpus\n",
        "all_words = []\n",
        "for x in spam['tokenized']:\n",
        "    all_words.extend(x)\n",
        "\n",
        "word_set = list(set(all_words))\n",
        "word_count = Counter(all_words)\n",
        "\n",
        "# filter out words with low frequency\n",
        "for word_list in spam.tokenized:\n",
        "    new_list = []\n",
        "    for word in word_list:\n",
        "        if word_count[word] > 2:\n",
        "            new_list.append(word)\n",
        "    word_list = new_list\n",
        "\n",
        "# update set of words after removing the ones with low frequency\n",
        "new_word_list = []\n",
        "for x in spam['tokenized']:\n",
        "    new_word_list.extend(x)\n",
        "word_set = list(set(new_word_list))\n",
        "\n",
        "# map each unique words & unknown token in reviews.encoded to an index\n",
        "word2index = {}\n",
        "word2index['<UNK>'] = 0\n",
        "word2index['<PAD>'] = 1\n",
        "\n",
        "for i, word in enumerate(word_set, 2):\n",
        "    word2index[word] = i\n",
        "\n",
        "# encode the original sequence\n",
        "def encode(sent_list):\n",
        "    result = []\n",
        "    for x in sent_list:\n",
        "        index = word2index[x]\n",
        "        result.append(index)\n",
        "    return result\n",
        "\n",
        "spam['encoded'] = spam.tokenized.apply(lambda x: encode(x))\n",
        "\n",
        "print(spam.head())\n",
        "\n",
        "# get sequence average length\n",
        "total_len = 0\n",
        "for x in spam.encoded:\n",
        "    total_len += len(x)\n",
        "\n",
        "ave_len = math.floor(total_len/spam.shape[0])\n",
        "\n",
        "# filter out long sequences --> encode all sequence to length = ave_len\n",
        "# pad short sequence\n",
        "\n",
        "for i, row in spam.iterrows():\n",
        "    size = min(len(row.encoded), ave_len)\n",
        "    new_encoded = row.encoded[:size]\n",
        "    if size < ave_len:\n",
        "        for j in range(0, ave_len - len(row.encoded)):\n",
        "            new_encoded.append(1)\n",
        "    spam.at[i, 'encoded'] = new_encoded\n",
        "\n",
        "spam['review_length'] = spam.encoded.apply(lambda x: len(x))\n"
      ],
      "metadata": {
        "id": "-sT1ynqj_7Fo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8aaa688-c66d-410f-9ecd-386f8af04cb0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             content  ...                                            encoded\n",
            "0  Go until jurong point, crazy.. Available only ...  ...  [3994, 6432, 3673, 4134, 2503, 3303, 5730, 93,...\n",
            "1                      Ok lar... Joking wif u oni...  ...                [3448, 5979, 7405, 708, 4183, 2668]\n",
            "2  Free entry in 2 a wkly comp to win FA Cup fina...  ...  [5916, 3174, 323, 6898, 4494, 5094, 8093, 5394...\n",
            "3  U dun say so early hor... U c already then say...  ...  [4183, 6827, 8449, 4495, 6120, 4183, 755, 5697...\n",
            "4  Nah I don't think he goes to usf, he lives aro...  ...          [5953, 1794, 5366, 4638, 6186, 4729, 958]\n",
            "\n",
            "[5 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sanity check for encoding:\n",
        "print(len(all_words))\n",
        "print(ave_len)\n",
        "lengths = [len(x) for x in spam.encoded]\n",
        "print(max(lengths))\n",
        "print(min(lengths))\n",
        "print(set(spam.detection))\n",
        "review_length = spam.review_length\n",
        "spam.head()\n",
        "print(len(word_set))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2326983-32f2-4f7a-caa7-f6b02af2683e",
        "id": "gsTWb6RQFzjX"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53413\n",
            "9\n",
            "9\n",
            "9\n",
            "{0, 1}\n",
            "8577\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Train test split from skearln\n",
        "# data_size = len(reviews['encoded'])\n",
        "# assert data_size == len(reviews['rating']) \n",
        "# X, y = list(zip(list(reviews['encoded']),(list(reviews['review_length'])))), list(reviews['rating'])\n",
        "# # X(data, length)\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=43)\n",
        "# Train test split from skearln\n",
        "data_size = len(spam['encoded'])\n",
        "assert data_size == len(spam['detection']) \n",
        "X, y = list(zip(list(spam['encoded']),(list(spam['review_length'])))), list(spam['detection'])\n",
        "# X(data, length)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=43)"
      ],
      "metadata": {
        "id": "glkjNVF-N_0r"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sanity check for length match\n",
        "print(X_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlveD7X5cPYp",
        "outputId": "686511ba-3aae-4b13-cff4-0081030784c0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "([7001, 1378, 7078, 5411, 5147, 1378, 7090, 1410, 4866], 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset and Dataloader"
      ],
      "metadata": {
        "id": "53k_akR7YiAl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clothing Review Dataset"
      ],
      "metadata": {
        "id": "5jGEsKl8obJ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset_word2vec(Dataset):\n",
        "    def __init__(self, X, y): \n",
        "        self.X = X\n",
        "\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return  self.X[idx], self.y[idx]"
      ],
      "metadata": {
        "id": "nmCLiMzCY-o3"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainSet_w2v = Dataset_word2vec(X_train, y_train)\n",
        "testSet_w2v = Dataset_word2vec(X_test, y_test)"
      ],
      "metadata": {
        "id": "yf03irQDieWM"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(trainSet_w2v[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCt282rkny8w",
        "outputId": "78e67e63-6cab-4954-a3c1-e91759de768f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(([7001, 1378, 7078, 5411, 5147, 1378, 7090, 1410, 4866], 9), 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def myCollate(batch):\n",
        "    data = [item[0] for item in batch]\n",
        "    label = [item[1] for item in batch]\n",
        "    # sort sequence according to it's length in a batch\n",
        "    data = data\n",
        "    # data.sort(key=lambda x: x[1], reverse = True)\n",
        "\n",
        "    # data (review: list, length: int)\n",
        "    review = torch.tensor([x[0] for x in data], dtype = torch.long)\n",
        "    label = torch.tensor(label, dtype = torch.long)\n",
        "    seq_len = [x[1] for x in data]\n",
        "    return review, label, seq_len"
      ],
      "metadata": {
        "id": "5UJ2oiTW8mYz"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainLoader_w2v = DataLoader(dataset = trainSet_w2v, batch_size = 16, collate_fn = myCollate, shuffle = True, drop_last = True)\n",
        "testLoader_w2v = DataLoader(dataset = testSet_w2v, batch_size = 16, collate_fn = myCollate, shuffle = True, drop_last = True)"
      ],
      "metadata": {
        "id": "17kzAjBchH_F"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "it = iter(trainLoader_w2v)\n",
        "x, y, seq_len = it.next()"
      ],
      "metadata": {
        "id": "nf1dmuSrfpWT"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxupL_Js1usD",
        "outputId": "ea6e55fc-68d7-49a9-d7e0-61afff969c1c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[5916, 3174, 7553, 6898, 4494, 8172, 3903, 5094, 7532],\n",
              "        [2625, 1816, 7306, 6826, 5375, 2890, 4229, 3855, 2421],\n",
              "        [6862, 7045, 2103, 6363,    1,    1,    1,    1,    1],\n",
              "        [4688, 3239, 6535, 7135, 1062, 2196,    1,    1,    1],\n",
              "        [2698, 3994, 4567, 3152, 7873, 7328,  908, 5531,    1],\n",
              "        [4294, 6123, 6088, 8285, 1816, 2976, 7580, 2371, 4183],\n",
              "        [2421, 4871, 5708, 2621, 2669, 2421, 6427,  567, 6918],\n",
              "        [3827,  883, 7717, 2931, 7482, 8315, 5111, 6969, 7510],\n",
              "        [8239, 2667, 4295, 1960,    1,    1,    1,    1,    1],\n",
              "        [3871, 8216, 8316, 1159, 4621, 6572, 2088, 3599, 6437],\n",
              "        [7909, 2552,  927, 2299, 5827, 6476, 6313,  456, 2799],\n",
              "        [7280, 7078, 6577, 5799, 7078, 5137, 1757, 7078, 6403],\n",
              "        [3684, 5076, 8285, 4703, 8285, 2153, 4183, 8215, 7602],\n",
              "        [2698, 6055, 6427, 3318, 2698, 4267,    1,    1,    1],\n",
              "        [6226, 2583, 5884, 5711, 1742, 4176,    1,    1,    1],\n",
              "        [3077,  445, 8213,  883, 3544, 5094,  674, 2634, 2121]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPW8bqg1th7a",
        "outputId": "2eba48bd-702b-42f3-d013-9c2c39608f4b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9PING33tjoJ",
        "outputId": "eeac15b1-58f9-423e-fdb6-f63d286bc6a2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embedding"
      ],
      "metadata": {
        "id": "dkOEB6jDYT2J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec = gensim.models.KeyedVectors.load_word2vec_format(\n",
        "    '/content/drive/MyDrive/data /GoogleNews-vectors-negative300.bin', binary = True)\n",
        "print(type(word2vec))\n",
        "weight = torch.FloatTensor(word2vec.vectors)\n",
        "word2vec_embedding = nn.Embedding.from_pretrained(weight)\n",
        "\n",
        "# sanity check for word2vec embedding\n",
        "temp = word2vec['hello', 'world']\n",
        "sanity_w2v = torch.Tensor(temp)\n",
        "print(sanity_w2v.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMAextiWYdVH",
        "outputId": "b0747588-ee10-46ed-f2f5-89f6448aa210"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'gensim.models.keyedvectors.Word2VecKeyedVectors'>\n",
            "torch.Size([2, 300])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create embedding matrix lstm\n",
        "def emb_matrix(model, all_words, word2index):\n",
        "    matrix_size = len(word_set) + 2\n",
        "    emb_matrix = np.zeros((matrix_size, 300))\n",
        "    emb_matrix[0] = np.random.uniform(-0.25, 0.25, 300) # vector for UNK\n",
        "    emb_matrix[1] = np.zeros(300) # vector for padding, has no weight\n",
        "\n",
        "    # vector for every other word in the dictionary\n",
        "    for i in range(2, len(all_words)+2):\n",
        "        word = all_words[i-2]\n",
        "        index = word2index[word]\n",
        "        try:\n",
        "            vector = model[word]\n",
        "        except Exception as e:\n",
        "            # word does not exist in the pretrained embedding\n",
        "            vector = emb_matrix[0]\n",
        "        emb_matrix[index] = vector\n",
        "    return emb_matrix"
      ],
      "metadata": {
        "id": "QRqGHAIJAgAx"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_w2v = emb_matrix(word2vec, word_set, word2index)"
      ],
      "metadata": {
        "id": "rKqasNfKXMQU"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(embedding.shape)"
      ],
      "metadata": {
        "id": "y1XRr66CXd76"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(embedding)"
      ],
      "metadata": {
        "id": "Axpw0w9DyznK"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validation_metrics(model, valid_dl):\n",
        "    print(\"current in vlaidaiton\")\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    sum_loss = 0.0\n",
        "    sum_rmse = 0.0\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    model = model\n",
        "    y_total = []\n",
        "    y_pred_total = []\n",
        "    for x, y, seq_len in valid_dl:\n",
        "        x = x.long()\n",
        "        y = y.long()\n",
        "        y_hat = model(x, seq_len)\n",
        "        loss = criterion(y_hat, y)\n",
        "        \n",
        "        # print(f\"shape of y: {y.shape}\")\n",
        "        # print(f\"shape of y_pred: {y_hat.shape}\")\n",
        "        # print(y_hat)\n",
        "        pred = torch.argmax(y_hat, 1)\n",
        "        y_total.extend(y.tolist())\n",
        "        y_pred_total.extend(pred.tolist())\n",
        "        \n",
        "        # print(pred)\n",
        "        correct += sum((pred == y))\n",
        "        total += y.shape[0]\n",
        "        sum_loss += loss.item()*y.shape[0]\n",
        "        # print(len(y_total))\n",
        "        # print(len(y_pred_total))\n",
        "\n",
        "      # calculate precision, recall, and f1\n",
        "    f1 = (f1_score(y_total, y_pred_total, average='weighted'))\n",
        "    precision = (precision_score(y_total, y_pred_total, average='weighted'))\n",
        "    recall =(recall_score(y_total, y_pred_total, average='weighted'))\n",
        "    return sum_loss/total, correct/total, precision, recall, f1"
      ],
      "metadata": {
        "id": "I40nbCLXlJt9"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, fname, epochs = 50, lr = 0.0001):\n",
        "    parameters = filter(lambda p:p.requires_grad, model.parameters())\n",
        "    optimizer = torch.optim.Adam(parameters, lr = lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    model = model\n",
        "    PATH = '/content/drive/MyDrive/McGill/Comp 550/' + fname\n",
        "    epoch = 0\n",
        "    best_val_acc = 0.0\n",
        "    for i in range(epochs):\n",
        "        epoch += 1\n",
        "        print(f\"At epoch {i}\")\n",
        "        batch_count = 0\n",
        "        model.train()\n",
        "        sum_loss = 0.0\n",
        "        total = 0.0\n",
        "        train_correct = 0.0\n",
        "        for x, y, seq_len in tqdm(trainLoader_w2v):\n",
        "            x = x.long()\n",
        "            y = y.long()\n",
        "            batch_count += 1\n",
        "            optimizer.zero_grad()\n",
        "            y_pred = model(x, seq_len)\n",
        "            pred = torch.argmax(y_pred, 1)\n",
        "            train_correct += sum((pred == y))\n",
        "            loss = criterion(y_pred, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            sum_loss += loss.item()*y.shape[0]\n",
        "            total += y.shape[0]\n",
        "        val_loss, val_acc, precision, recall, f1 = validation_metrics(model, testLoader_w2v)\n",
        "        print(\"train loss %.3f, train accuracy %.3f, val loss %.3f, val accuracy %.3f, precision %.3f, recall %.3f, F1 %.3f\" \n",
        "              % (sum_loss/total, train_correct/total, val_loss, val_acc, precision, recall, f1))\n",
        "        if val_acc > best_val_acc and i>=1:\n",
        "            best_val_acc = val_acc\n",
        "            NEW_PATH = PATH+f'_{i}_{val_acc}.pth'\n",
        "            #torch.save(model.state_dict(), NEW_PATH)\n",
        "            print(f\"\\t=> Best model saved at {i}th epoch with valication accuracy of {val_acc}\")"
      ],
      "metadata": {
        "id": "YVwWS3rRnOw0"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight = torch.FloatTensor(word2vec.vectors)\n",
        "word2vec_embedding = nn.Embedding.from_pretrained(weight)\n",
        "\n",
        "class LSTM_word2vec(torch.nn.Module):\n",
        "    def __init__(self, emb_matrix, embedding_dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.embeddings = nn.Embedding(emb_matrix.shape[0], embedding_dim, padding_idx = 0)\n",
        "        self.embeddings.weight.data.copy_(torch.from_numpy(emb_matrix))\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.linear = nn.Linear(hidden_dim, 5)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, x, seq_len):\n",
        "        x = self.embeddings(x)\n",
        "        # x = nn.utils.rnn.pack_padded_sequence(x, self.embedding_dim, batch_first = True)\n",
        "        x = self.dropout(x)\n",
        "        # x_padded = pack_padded_sequence(x, seq_len, batch_first = True)\n",
        "        output, (h_n, c_n) = self.lstm(x)\n",
        "        # print(h_n[-1].shape)\n",
        "        # output (N, ave_len, num_class)\n",
        "        # reshape to out (N, num_class)\n",
        "        \n",
        "        return self.linear(h_n[-1])"
      ],
      "metadata": {
        "id": "w1y9PO6JW28H"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# distil_bert = 'distilbert-base-uncased'\n",
        "#         #config = DistilBertConfig(dropout=0.2, attention_dropout=0.2)\n",
        "#         #config.output_hidden_states = False\n",
        "# transformer_model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "        \n",
        "# embedding =  list(transformer_model.children())[0]\n",
        "# bert_word_embeddings = list(embedding.children())[0]"
      ],
      "metadata": {
        "id": "j09LcerVrHTi"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class LSTM_fixed_length_Bert(torch.nn.Module) :\n",
        "#     def __init__(self, vocab_size, embedding_dim, hidden_dim) :\n",
        "#         super().__init__()\n",
        "#         self.embeddings = bert_word_embeddings\n",
        "#         self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "#         self.linear = nn.Linear(hidden_dim, 5)\n",
        "#         self.dropout = nn.Dropout(0.5)\n",
        "        \n",
        "#     def forward(self, x, l):\n",
        "#         x = self.embeddings(x)\n",
        "#         x = self.dropout(x)\n",
        "#         lstm_out, (ht, ct) = self.lstm(x)\n",
        "#         return self.linear(ht[-1])"
      ],
      "metadata": {
        "id": "dTueiq-CqPRZ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model_bert = LSTM_fixed_length_Bert(len(word_set), 768, 50)\n",
        "# train_model(model_bert, fname = 'bert_lstm_clothing', epochs = 30)"
      ],
      "metadata": {
        "id": "fACGMEuvsToN"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTM_word2vec(embeddings_w2v, 300, 100)\n",
        "train_model(model, fname='word2vec_lstm', epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xShR5nvtlxXV",
        "outputId": "92d346c4-bf7d-4a2e-809a-eb2f1544d261"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "At epoch 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 278/278 [00:05<00:00, 49.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current in vlaidaiton\n",
            "train loss 0.815, train accuracy 0.748, val loss 0.313, val accuracy 0.872, precision 0.879, recall 0.872, F1 0.823\n",
            "At epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 278/278 [00:05<00:00, 53.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current in vlaidaiton\n",
            "train loss 0.185, train accuracy 0.936, val loss 0.139, val accuracy 0.954, precision 0.953, recall 0.954, F1 0.953\n",
            "\t=> Best model saved at 1th epoch with valication accuracy of 0.9538043737411499\n",
            "At epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 278/278 [00:05<00:00, 54.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current in vlaidaiton\n",
            "train loss 0.097, train accuracy 0.971, val loss 0.100, val accuracy 0.965, precision 0.964, recall 0.965, F1 0.965\n",
            "\t=> Best model saved at 2th epoch with valication accuracy of 0.9646739363670349\n",
            "At epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 278/278 [00:05<00:00, 53.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current in vlaidaiton\n",
            "train loss 0.067, train accuracy 0.980, val loss 0.080, val accuracy 0.972, precision 0.972, recall 0.972, F1 0.972\n",
            "\t=> Best model saved at 3th epoch with valication accuracy of 0.9719203114509583\n",
            "At epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 278/278 [00:05<00:00, 53.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current in vlaidaiton\n",
            "train loss 0.050, train accuracy 0.986, val loss 0.071, val accuracy 0.975, precision 0.974, recall 0.975, F1 0.974\n",
            "\t=> Best model saved at 4th epoch with valication accuracy of 0.9746376872062683\n",
            "At epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 278/278 [00:05<00:00, 53.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current in vlaidaiton\n",
            "train loss 0.038, train accuracy 0.990, val loss 0.068, val accuracy 0.975, precision 0.974, recall 0.975, F1 0.974\n",
            "At epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 278/278 [00:05<00:00, 53.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current in vlaidaiton\n",
            "train loss 0.029, train accuracy 0.993, val loss 0.076, val accuracy 0.972, precision 0.972, recall 0.972, F1 0.971\n",
            "At epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 278/278 [00:05<00:00, 53.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current in vlaidaiton\n",
            "train loss 0.020, train accuracy 0.996, val loss 0.076, val accuracy 0.975, precision 0.974, recall 0.975, F1 0.974\n",
            "At epoch 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 278/278 [00:05<00:00, 53.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current in vlaidaiton\n",
            "train loss 0.018, train accuracy 0.996, val loss 0.071, val accuracy 0.976, precision 0.975, recall 0.976, F1 0.975\n",
            "\t=> Best model saved at 8th epoch with valication accuracy of 0.9755434989929199\n",
            "At epoch 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 278/278 [00:05<00:00, 53.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current in vlaidaiton\n",
            "train loss 0.013, train accuracy 0.998, val loss 0.073, val accuracy 0.976, precision 0.976, recall 0.976, F1 0.976\n",
            "\t=> Best model saved at 9th epoch with valication accuracy of 0.9764492511749268\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "s0P-MnfwynbQ"
      },
      "execution_count": 35,
      "outputs": []
    }
  ]
}